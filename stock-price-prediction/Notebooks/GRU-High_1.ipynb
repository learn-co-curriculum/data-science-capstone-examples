{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 81
    },
    "colab_type": "code",
    "id": "ECYu4kAkx5Bc",
    "outputId": "6125f8ba-fe25-4b43-c5b2-3339f3d9d21b",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import datetime\n",
    "import json\n",
    "#import pandas_datareader as pdr\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from keras import models\n",
    "from keras import layers\n",
    "from keras import optimizers\n",
    "from matplotlib.image import imread\n",
    "from keras.preprocessing import image\n",
    "from sklearn.metrics import r2_score\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "DlJQtfuxx5Bl"
   },
   "source": [
    "### Pulling stock list from Virtus LifeSci Biotech ETF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Hrrzwx3cx5Bn"
   },
   "outputs": [],
   "source": [
    "stocks = ['ITCI', 'AXSM', 'CVM', 'KRTX', 'APLS', 'PRVB', 'CRTX', 'EPZM',\n",
    "       'CRBP', 'CCXI', 'TGTX', 'IMGN', 'FATE', 'AKBA', 'DNLI', 'RIGL',\n",
    "       'PRNB', 'ARVN', 'ZYME', 'MRNA', 'CYTK', 'FTSV', 'ASND',\n",
    "       'XBIT', 'ALEC', 'ORTX', 'ADVM', 'MGNX', 'AKRO', 'ESPR', 'BHVN',\n",
    "       'YMAB', 'RGNX', 'MYOK', 'TPTX', 'ATNX', 'BLUE', 'AGEN', 'AVRO',\n",
    "       'DCPH', 'CTMX', 'SRNE', 'ARDX', 'BCRX', 'RETA', 'KOD', 'DTIL',\n",
    "       'RARX', 'AUTL', 'GTHX', 'CARA', 'KDMN', 'XNCR', 'ACHN', 'ARNA',\n",
    "       'RCKT', 'TBIO', 'VYGR', 'SGMO', 'ODT', 'ANAB', 'ATRA', 'CNST',\n",
    "       'GERN', 'BPMC', 'ALLO', 'BBIO', 'FGEN', 'PGNX', 'MGTX', 'NXTC',\n",
    "       'IMMU', 'ZIOP', 'CRSP', 'IOVA', 'VKTX', 'EIDX', 'MYOV', 'AMRS',\n",
    "       'KRYS', 'KURA', 'MDGL', 'UBX', 'TCDA', 'QURE', 'MRTX', 'ASMB',\n",
    "       'GLYC', 'RYTM', 'FIXX', 'DRNA', 'ARWR', 'ALLK', 'GOSS', 'WVE']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('1_31_2020_pull.json', 'r') as file:\n",
    "    data = json.load(file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "start = datetime.datetime.now()\n",
    "period = [1, 2]\n",
    "for stock in stocks:\n",
    "    \n",
    "    stock_dict_list = data[stock]\n",
    "    num_days = len(stock_dict_list)\n",
    "    for index, dict_ in enumerate(stock_dict_list):\n",
    "        _open = dict_['Open']\n",
    "        if index+period[1] >= num_days:\n",
    "            _low = None\n",
    "            _max = None\n",
    "        else:\n",
    "            _low = np.min([dict_['Low'] for dict_ in stock_dict_list[index+period[0]:index+period[1]]])/ _open -1\n",
    "            _max = np.max([dict_['High'] for dict_ in stock_dict_list[index+period[0]:index+period[1]]])/ _open -1\n",
    "        stock_dict_list[index]['Low_1'] = _low\n",
    "        stock_dict_list[index]['Max_1'] = _max\n",
    "        \n",
    "        #Moving Average 10\n",
    "        if index- 10 >=0:\n",
    "            average = np.mean([dict_['Open'] for dict_ in stock_dict_list[index-10:index]])\n",
    "        else:\n",
    "            average = None\n",
    "        stock_dict_list[index]['Moving10'] = average\n",
    "        \n",
    "        #Moving Average 30\n",
    "        if index- 30 >=0:\n",
    "            average = np.mean([dict_['Open'] for dict_ in stock_dict_list[index-30:index]])\n",
    "        else:\n",
    "            average = None\n",
    "        stock_dict_list[index]['Moving30'] = average\n",
    "        \n",
    "    data[stock] = stock_dict_list\n",
    "\n",
    "# # 3 Day Max/Min Value (% Difference from Closing Price)\n",
    "# # The range is from the 2nd day to the 3rd after the input day\n",
    "# start = datetime.datetime.now()\n",
    "# period = [2, 4]\n",
    "# for stock in stocks:\n",
    "    \n",
    "#     stock_dict_list = data[stock]\n",
    "#     num_days = len(stock_dict_list)\n",
    "#     for index, dict_ in enumerate(stock_dict_list):\n",
    "#         _open = dict_['Open']\n",
    "#         if index+period[1] >= num_days:\n",
    "#             _low = None\n",
    "#             _max = None\n",
    "#         else:\n",
    "#             _low = np.min([dict_['Low'] for dict_ in stock_dict_list[index+period[0]:index+period[1]]])/ _open -1\n",
    "#             _max = np.max([dict_['High'] for dict_ in stock_dict_list[index+period[0]:index+period[1]]])/ _open -1\n",
    "#         stock_dict_list[index]['Low_3'] = _low\n",
    "#         stock_dict_list[index]['Max_3'] = _max\n",
    "#     data[stock] = stock_dict_list\n",
    "\n",
    "# # 10 Day Max/Min Value (% Difference from Closing Price)\n",
    "# # The range is from the 4th day to the 10th after the input day\n",
    "\n",
    "# start = datetime.datetime.now()\n",
    "# period = [4, 11]\n",
    "# for stock in stocks:\n",
    "    \n",
    "#     stock_dict_list = data[stock]\n",
    "#     num_days = len(stock_dict_list)\n",
    "#     for index, dict_ in enumerate(stock_dict_list):\n",
    "#         _open = dict_['Open']\n",
    "#         if index+period[1] >= num_days:\n",
    "#             _low = None\n",
    "#             _max = None\n",
    "#         else:\n",
    "#             _low = np.min([dict_['Low'] for dict_ in stock_dict_list[index+period[0]:index+period[1]]])/ _open -1\n",
    "#             _max = np.max([dict_['High'] for dict_ in stock_dict_list[index+period[0]:index+period[1]]])/ _open -1\n",
    "#         stock_dict_list[index]['Low_10'] = _low\n",
    "#         stock_dict_list[index]['Max_10'] = _max\n",
    "#     data[stock] = stock_dict_list\n",
    "\n",
    "# # 30 Day Max/Min Value (% Difference from Closing Price)\n",
    "# # The range is from the 11th day to the 30th after the input day\n",
    "# start = datetime.datetime.now()\n",
    "# period = [11, 31]\n",
    "# for stock in stocks:\n",
    "    \n",
    "#     stock_dict_list = data[stock]\n",
    "#     num_days = len(stock_dict_list)\n",
    "#     for index, dict_ in enumerate(stock_dict_list):\n",
    "#         _open = dict_['Open']\n",
    "#         if index+period[1] >= num_days:\n",
    "#             _low = None\n",
    "#             _max = None\n",
    "#         else:\n",
    "#             _low = np.min([dict_['Low'] for dict_ in stock_dict_list[index+period[0]:index+period[1]]])/ _open -1\n",
    "#             _max = np.max([dict_['High'] for dict_ in stock_dict_list[index+period[0]:index+period[1]]])/ _open -1\n",
    "#         stock_dict_list[index]['Low_30'] = _low\n",
    "#         stock_dict_list[index]['Max_30'] = _max\n",
    "#     data[stock] = stock_dict_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for stock in stocks:\n",
    "    df = pd.DataFrame(data[stock])\n",
    "    max_value = df[['High', 'Low', 'Open', 'Close', 'Adj Close', 'Moving10', 'Moving30']].max()\n",
    "    df[['High', 'Low', 'Open', 'Close', 'Adj Close', 'Moving10', 'Moving30']] = df[['High', 'Low', 'Open', 'Close', 'Adj Close', 'Moving10', 'Moving30']]/max_value\n",
    "    df['Volume'] = df['Volume']/ df['Volume'].max()\n",
    "    df= df.dropna()\n",
    "    \n",
    "    data[stock] = df.to_dict('records')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_in_list = []\n",
    "for stock in stocks:\n",
    "    stock_dict_list = data[stock]\n",
    "    for index, dict_ in enumerate(stock_dict_list):\n",
    "        list_ = [0, 0, 0, 0, 0, 0, 0, 0]\n",
    "        if dict_['Max_1'] <= 0:\n",
    "            list_[0] = 1      \n",
    "        else:\n",
    "            if dict_['Max_1'] <= 0.02:\n",
    "                list_[1] = 1\n",
    "            else:\n",
    "                if dict_['Max_1'] <= 0.04:\n",
    "                    list_[2] = 1\n",
    "                else:\n",
    "                    if dict_['Max_1'] <= 0.06:\n",
    "                        list_[3] = 1\n",
    "                    else:\n",
    "                        if dict_['Max_1'] <= 0.08:\n",
    "                            list_[4] = 1\n",
    "                        else:\n",
    "                            if dict_['Max_1'] <= 0.10:\n",
    "                                list_[5] = 1\n",
    "                            else:\n",
    "                                if dict_['Max_1'] < 0.12:\n",
    "                                    list_[6] = 1\n",
    "                                else:\n",
    "                                    list_[7] = 1\n",
    "        stock_dict_list[index]['High_1'] = list_\n",
    "        dict_['High_1'] = list_\n",
    "        data_in_list.append(dict_)\n",
    "    data[stock] = stock_dict_list\n",
    "df = pd.DataFrame(data_in_list) \n",
    "df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "DLYnbjYeyu0y"
   },
   "outputs": [],
   "source": [
    "processed_data = {}\n",
    "\n",
    "for stock in stocks:\n",
    "    x = []\n",
    "    target = []\n",
    "    dict_ = {}\n",
    "    for i in data[stock]:\n",
    "        row =np.array([i['High'], i['Low'], i['Open'], i['Close'], i['Adj Close'], i['Volume'], i['Moving10'], i['Moving30']])\n",
    "        x.append(row)\n",
    "        row = np.array(i['High_1'])\n",
    "        target.append(row)\n",
    "    dict_['Data'] = x\n",
    "    dict_['Target'] = target\n",
    "    processed_data[stock] = dict_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "mxB68JDiJZ7M"
   },
   "outputs": [],
   "source": [
    "for stock in stocks:\n",
    "    length_ = len(processed_data[stock]['Data'])\n",
    "    length_test = len(processed_data[stock]['Data'])//8\n",
    "    test_start = length_- 50\n",
    "    test_end = length_test+ test_start\n",
    "    processed_data[stock]['data_1'] = np.array(processed_data[stock]['Data'][:test_start])\n",
    "    processed_data[stock]['data_1'] =   processed_data[stock]['data_1'].reshape(len(processed_data[stock]['data_1']), 1, 8)\n",
    "    processed_data[stock]['data_test'] = np.array(processed_data[stock]['Data'][test_start:-10])\n",
    "    processed_data[stock]['data_test'] = processed_data[stock]['data_test'].reshape(len(processed_data[stock]['data_test']),1,8)\n",
    "    transfer_list = np.array(processed_data[stock]['Target'][:test_start])\n",
    "    processed_data[stock]['target_1'] =transfer_list.reshape(len(transfer_list), 8)\n",
    "    transfer_list = np.array(processed_data[stock]['Target'][test_start:-10])\n",
    "    processed_data[stock]['target_test'] = transfer_list.reshape(len(transfer_list),8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 266
    },
    "colab_type": "code",
    "id": "gxJmCXmt6DjZ",
    "outputId": "4cce03cc-ade7-4139-a9c6-f2e194a2f754"
   },
   "outputs": [],
   "source": [
    "model = models.Sequential()\n",
    "model.add(layers.GRU(50, return_sequences=True, input_shape=(1,8)))\n",
    "model.add(layers.Dropout(0.2))\n",
    "model.add(layers.GRU(1000, return_sequences=False))\n",
    "model.add(layers.Dropout(0.2))\n",
    "model.add(layers.Dense(8, activation = \"softmax\"))\n",
    "model.compile(loss='categorical_crossentropy',\n",
    "              optimizer='adam', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "epochs = 100\n",
    "for stock in stocks:\n",
    "    (feature_train, label_train, feature_test, label_test) = (processed_data[stock]['data_1'],processed_data[stock]['target_1'], \n",
    "                                                                    processed_data[stock]['data_test'],\n",
    "                                                              processed_data[stock]['target_test']) \n",
    "    model.fit(feature_train, label_train, batch_size=25, epochs=epochs, \n",
    "              validation_data = (feature_test, label_test), verbose=0)\n",
    "    dict_ = model.history.history\n",
    "    plt.figure(figsize=(8,5))\n",
    "    plt.title(f\"{stock} {epochs} Epochs Loss\")\n",
    "    plt.plot(dict_['loss'], label = 'Loss')\n",
    "    plt.plot(dict_['val_loss'], label= 'Validation Loss')\n",
    "    plt.legend(bbox_to_anchor=(1.05, 1))\n",
    "    plt.show()\n",
    "    plt.figure(figsize=(8,5))\n",
    "    plt.title(f\"{stock} {epochs} Epochs Accuracy\")\n",
    "    plt.plot(dict_['acc'], label = 'Accuracy')\n",
    "    plt.plot(dict_['val_acc'], label= 'Validation Accuracy')\n",
    "    plt.legend(bbox_to_anchor=(1.05, 1))\n",
    "    plt.show() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "colab_type": "code",
    "id": "gWTDi1NMBdIe",
    "outputId": "dc3859c3-8a10-4841-88e9-1d5cba68295d",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "epochs = 1000\n",
    "\n",
    "    \n",
    "\n",
    "stock = 'SGMO'\n",
    "(feature_train, label_train, feature_test, label_test) = (processed_data[stock]['data_1'],processed_data[stock]['target_1'], \n",
    "                                                                processed_data[stock]['data_test'], processed_data[stock]['target_test']) \n",
    "model.fit(feature_train, label_train, batch_size=25, epochs=epochs, validation_data = (feature_test, label_test), verbose=0)\n",
    "dict_ = model.history.history\n",
    "plt.figure(figsize=(8,5))\n",
    "plt.title(f\"{stock} {epochs} Epochs Loss\")\n",
    "plt.plot(dict_['loss'], label = 'Loss')\n",
    "plt.plot(dict_['val_loss'], label= 'Validation Loss')\n",
    "plt.legend(bbox_to_anchor=(1.05, 1))\n",
    "plt.show()\n",
    "plt.figure(figsize=(8,5))\n",
    "plt.title(f\"{stock} {epochs} Epochs Accuracy\")\n",
    "plt.plot(dict_['acc'], label = 'Accuracy')\n",
    "plt.plot(dict_['val_acc'], label= 'Validation Accuracy')\n",
    "plt.legend(bbox_to_anchor=(1.05, 1))\n",
    "plt.show()\n",
    "filepath = f\"Model_GRU_cat_High1{epochs}.h5\"\n",
    "    \n",
    "model.save_weights(filepath)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import label_ranking_average_precision_score, coverage_error, label_ranking_average_precision_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "list_= []\n",
    "predict_list = []\n",
    "true_list = []\n",
    "for stock in stocks:\n",
    "    X = np.array(processed_data[stock]['Data']).reshape(len(processed_data[stock]['Data']), 1, 8)\n",
    "    predict = model.predict(X)\n",
    "    for index, i in enumerate(predict):\n",
    "        predict_list.append(i)\n",
    "        true_list.append(processed_data[stock]['Target'][index])\n",
    "    list_.append({'Ticker':stock, 'Ranking':label_ranking_average_precision_score(processed_data[stock]['Target'], predict)})\n",
    "                  \n",
    "df = pd.DataFrame(list_)\n",
    "df.sort_values('Ranking', ascending=False).head(15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "columns=['Under 0%', '0.5%', '1.5%', '3%', '5%', '7%', '9%', 'Over 10%']\n",
    "\n",
    "for column, name in enumerate(columns):\n",
    "    \n",
    "    transfer_list = []\n",
    "    for index, target in enumerate(true_list):\n",
    "        if target[column] == 1:\n",
    "            transfer_list.append(predict_list[index])\n",
    "    plt.figure(figsize=(8,5))\n",
    "    pd.DataFrame(transfer_list, columns=columns).mean().plot.bar().set_title(name)\n",
    "    plt.vlines(column, 0,.5)\n",
    "    plt.show"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "X = np.array(processed_data['SGMO']['Data']).reshape(len(processed_data['SGMO']['Data']), 1, 8)\n",
    "predict = model.predict(X)\n",
    "transfer_list = []\n",
    "for column, name in enumerate(columns):\n",
    "    for index, target in enumerate(processed_data['SGMO']['Target']):\n",
    "        if target[column] == 1:\n",
    "            transfer_list.append(predict[index])\n",
    "    plt.figure(figsize=(8,5))\n",
    "    pd.DataFrame(transfer_list, columns=columns).mean().plot.bar().set_title(name)\n",
    "    plt.vlines(column, 0,.5)\n",
    "    plt.show   \n",
    "                  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "name": "data_retrieval.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
