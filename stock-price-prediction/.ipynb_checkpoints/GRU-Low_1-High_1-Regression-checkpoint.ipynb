{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 81
    },
    "colab_type": "code",
    "id": "ECYu4kAkx5Bc",
    "outputId": "6125f8ba-fe25-4b43-c5b2-3339f3d9d21b",
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import datetime\n",
    "import json\n",
    "#import pandas_datareader as pdr\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from keras import models\n",
    "from keras import layers\n",
    "from keras import optimizers\n",
    "from matplotlib.image import imread\n",
    "from keras.preprocessing import image\n",
    "from sklearn.metrics import r2_score\n",
    "import seaborn as sns\n",
    "sns.set_style(\"darkgrid\")\n",
    "from sklearn.metrics import label_ranking_average_precision_score, coverage_error, label_ranking_average_precision_score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "DlJQtfuxx5Bl"
   },
   "source": [
    "### Pulling stock list from Virtus LifeSci Biotech ETF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Hrrzwx3cx5Bn"
   },
   "outputs": [],
   "source": [
    "stocks = ['ITCI', 'AXSM', 'CVM', 'KRTX', 'APLS', 'PRVB', 'CRTX', 'EPZM',\n",
    "       'CRBP', 'CCXI', 'TGTX', 'IMGN', 'FATE', 'AKBA', 'DNLI', 'RIGL',\n",
    "       'PRNB', 'ARVN', 'ZYME', 'MRNA', 'CYTK', 'FTSV', 'ASND',\n",
    "       'XBIT', 'ALEC', 'ORTX', 'ADVM', 'MGNX', 'AKRO', 'ESPR', 'BHVN',\n",
    "       'YMAB', 'RGNX', 'MYOK', 'TPTX', 'ATNX', 'BLUE', 'AGEN', 'AVRO',\n",
    "       'DCPH', 'CTMX', 'SRNE', 'ARDX', 'BCRX', 'RETA', 'KOD', 'DTIL',\n",
    "       'RARX', 'AUTL', 'GTHX', 'CARA', 'KDMN', 'XNCR', 'ACHN', 'ARNA',\n",
    "       'RCKT', 'TBIO', 'VYGR', 'SGMO', 'ODT', 'ANAB', 'ATRA', 'CNST',\n",
    "       'GERN', 'BPMC', 'ALLO', 'BBIO', 'FGEN', 'PGNX', 'MGTX', 'NXTC',\n",
    "       'IMMU', 'ZIOP', 'CRSP', 'IOVA', 'VKTX', 'EIDX', 'MYOV', 'AMRS',\n",
    "       'KRYS', 'KURA', 'MDGL', 'UBX', 'TCDA', 'QURE', 'MRTX', 'ASMB',\n",
    "       'GLYC', 'RYTM', 'FIXX', 'DRNA', 'ARWR', 'ALLK', 'GOSS', 'WVE']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('1_31_2020_pull.json', 'r') as file:\n",
    "    data = json.load(file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "low_range = [-10, 5]\n",
    "high_range = [-3, 13]\n",
    "start = datetime.datetime.now()\n",
    "period = [1, 2]\n",
    "for stock in stocks:\n",
    "    \n",
    "    stock_dict_list = data[stock]\n",
    "    num_days = len(stock_dict_list)\n",
    "    for index, dict_ in enumerate(stock_dict_list):\n",
    "        _open = dict_['Open']\n",
    "        if index>0:\n",
    "            percent_change = (stock_dict_list[index-1]['Open']-_open)/ stock_dict_list[index-1]['Open']\n",
    "            stock_dict_list[index]['%_Change'] = percent_change\n",
    "        if index+period[1] >= num_days:\n",
    "            _low = None\n",
    "            _max = None\n",
    "        else:\n",
    "            _low = np.min([dict_['Low'] for dict_ in stock_dict_list[index+period[0]:index+period[1]]])/ _open -1\n",
    "            if _low <= low_range[0]/100:\n",
    "                _low = low_range[0]/100\n",
    "            if _low >= (low_range[1]-1)/100:\n",
    "                _low = (low_range[1]-1)/100\n",
    "            \n",
    "            _max = np.max([dict_['High'] for dict_ in stock_dict_list[index+period[0]:index+period[1]]])/ _open -1\n",
    "            if _max <= high_range[0]/100:\n",
    "                _max = high_range[0]/100\n",
    "            if _max >= (high_range[1]-1)/100:\n",
    "                _max = (high_range[1]-1)/100\n",
    "            _low = round(_low,2)\n",
    "            _max = round(_max, 2)\n",
    "        stock_dict_list[index]['Low_1'] = _low\n",
    "        stock_dict_list[index]['Max_1'] = _max\n",
    "        \n",
    "        #Moving Average 10\n",
    "        if index- 10 >=0:\n",
    "            average = np.mean([dict_['Open'] for dict_ in stock_dict_list[index-10:index]])\n",
    "        else:\n",
    "            average = None\n",
    "        stock_dict_list[index]['Moving10'] = average\n",
    "        \n",
    "        #Moving Average 30\n",
    "        if index- 30 >=0:\n",
    "            average = np.mean([dict_['Open'] for dict_ in stock_dict_list[index-30:index]])\n",
    "        else:\n",
    "            average = None\n",
    "        stock_dict_list[index]['Moving30'] = average\n",
    "        \n",
    "    data[stock] = stock_dict_list\n",
    "\n",
    "# # 3 Day Max/Min Value (% Difference from Closing Price)\n",
    "# # The range is from the 2nd day to the 3rd after the input day\n",
    "# start = datetime.datetime.now()\n",
    "# period = [2, 4]\n",
    "# for stock in stocks:\n",
    "    \n",
    "#     stock_dict_list = data[stock]\n",
    "#     num_days = len(stock_dict_list)\n",
    "#     for index, dict_ in enumerate(stock_dict_list):\n",
    "#         _open = dict_['Open']\n",
    "#         if index+period[1] >= num_days:\n",
    "#             _low = None\n",
    "#             _max = None\n",
    "#         else:\n",
    "#             _low = np.min([dict_['Low'] for dict_ in stock_dict_list[index+period[0]:index+period[1]]])/ _open -1\n",
    "#             _max = np.max([dict_['High'] for dict_ in stock_dict_list[index+period[0]:index+period[1]]])/ _open -1\n",
    "#         stock_dict_list[index]['Low_3'] = _low\n",
    "#         stock_dict_list[index]['Max_3'] = _max\n",
    "#     data[stock] = stock_dict_list\n",
    "\n",
    "# # 10 Day Max/Min Value (% Difference from Closing Price)\n",
    "# # The range is from the 4th day to the 10th after the input day\n",
    "\n",
    "# start = datetime.datetime.now()\n",
    "# period = [4, 11]\n",
    "# for stock in stocks:\n",
    "    \n",
    "#     stock_dict_list = data[stock]\n",
    "#     num_days = len(stock_dict_list)\n",
    "#     for index, dict_ in enumerate(stock_dict_list):\n",
    "#         _open = dict_['Open']\n",
    "#         if index+period[1] >= num_days:\n",
    "#             _low = None\n",
    "#             _max = None\n",
    "#         else:\n",
    "#             _low = np.min([dict_['Low'] for dict_ in stock_dict_list[index+period[0]:index+period[1]]])/ _open -1\n",
    "#             _max = np.max([dict_['High'] for dict_ in stock_dict_list[index+period[0]:index+period[1]]])/ _open -1\n",
    "#         stock_dict_list[index]['Low_10'] = _low\n",
    "#         stock_dict_list[index]['Max_10'] = _max\n",
    "#     data[stock] = stock_dict_list\n",
    "\n",
    "# # 30 Day Max/Min Value (% Difference from Closing Price)\n",
    "# # The range is from the 11th day to the 30th after the input day\n",
    "# start = datetime.datetime.now()\n",
    "# period = [11, 31]\n",
    "# for stock in stocks:\n",
    "    \n",
    "#     stock_dict_list = data[stock]\n",
    "#     num_days = len(stock_dict_list)\n",
    "#     for index, dict_ in enumerate(stock_dict_list):\n",
    "#         _open = dict_['Open']\n",
    "#         if index+period[1] >= num_days:\n",
    "#             _low = None\n",
    "#             _max = None\n",
    "#         else:\n",
    "#             _low = np.min([dict_['Low'] for dict_ in stock_dict_list[index+period[0]:index+period[1]]])/ _open -1\n",
    "#             _max = np.max([dict_['High'] for dict_ in stock_dict_list[index+period[0]:index+period[1]]])/ _open -1\n",
    "#         stock_dict_list[index]['Low_30'] = _low\n",
    "#         stock_dict_list[index]['Max_30'] = _max\n",
    "#     data[stock] = stock_dict_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "for stock in stocks:\n",
    "    df = pd.DataFrame(data[stock])\n",
    "    max_value = df[['High', 'Low', 'Open', 'Close', 'Adj Close', 'Moving10', 'Moving30']].max()\n",
    "    df[['High', 'Low', 'Open', 'Close', 'Adj Close', 'Moving10', 'Moving30']] = df[['High', 'Low', 'Open', 'Close',\n",
    "                                                                                    'Adj Close', 'Moving10', 'Moving30']]/max_value\n",
    "    df['Volume'] = df['Volume']/ df['Volume'].max()\n",
    "    df= df.dropna()\n",
    "    \n",
    "    \n",
    "    data[stock] = df.to_dict('records')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[-3, -2, -1, 0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(range(high_range[0],high_range[1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>%_Change</th>\n",
       "      <th>Adj Close</th>\n",
       "      <th>Close</th>\n",
       "      <th>High</th>\n",
       "      <th>Low</th>\n",
       "      <th>Low_1</th>\n",
       "      <th>Max_1</th>\n",
       "      <th>Moving10</th>\n",
       "      <th>Moving30</th>\n",
       "      <th>Open</th>\n",
       "      <th>Volume</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>145249.000000</td>\n",
       "      <td>145249.000000</td>\n",
       "      <td>145249.000000</td>\n",
       "      <td>145249.000000</td>\n",
       "      <td>145249.000000</td>\n",
       "      <td>145249.000000</td>\n",
       "      <td>145249.000000</td>\n",
       "      <td>145249.000000</td>\n",
       "      <td>145249.000000</td>\n",
       "      <td>145249.000000</td>\n",
       "      <td>145249.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>-14.587246</td>\n",
       "      <td>0.260711</td>\n",
       "      <td>0.260711</td>\n",
       "      <td>0.258983</td>\n",
       "      <td>0.262354</td>\n",
       "      <td>-0.028830</td>\n",
       "      <td>0.029378</td>\n",
       "      <td>0.280289</td>\n",
       "      <td>0.300724</td>\n",
       "      <td>0.259255</td>\n",
       "      <td>0.026125</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>241.445658</td>\n",
       "      <td>0.233928</td>\n",
       "      <td>0.233928</td>\n",
       "      <td>0.233008</td>\n",
       "      <td>0.234513</td>\n",
       "      <td>0.039775</td>\n",
       "      <td>0.043007</td>\n",
       "      <td>0.244531</td>\n",
       "      <td>0.256038</td>\n",
       "      <td>0.233414</td>\n",
       "      <td>0.050913</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>-6817.181855</td>\n",
       "      <td>0.000002</td>\n",
       "      <td>0.000002</td>\n",
       "      <td>0.000003</td>\n",
       "      <td>0.000002</td>\n",
       "      <td>-0.100000</td>\n",
       "      <td>-0.030000</td>\n",
       "      <td>0.000006</td>\n",
       "      <td>0.000482</td>\n",
       "      <td>0.000003</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>-0.022472</td>\n",
       "      <td>0.071907</td>\n",
       "      <td>0.071907</td>\n",
       "      <td>0.071415</td>\n",
       "      <td>0.073402</td>\n",
       "      <td>-0.060000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.082165</td>\n",
       "      <td>0.091947</td>\n",
       "      <td>0.071223</td>\n",
       "      <td>0.002690</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.186074</td>\n",
       "      <td>0.186074</td>\n",
       "      <td>0.183905</td>\n",
       "      <td>0.187259</td>\n",
       "      <td>-0.030000</td>\n",
       "      <td>0.020000</td>\n",
       "      <td>0.203135</td>\n",
       "      <td>0.222163</td>\n",
       "      <td>0.183868</td>\n",
       "      <td>0.011252</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>0.023364</td>\n",
       "      <td>0.387178</td>\n",
       "      <td>0.387178</td>\n",
       "      <td>0.384500</td>\n",
       "      <td>0.387692</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.050000</td>\n",
       "      <td>0.414505</td>\n",
       "      <td>0.448409</td>\n",
       "      <td>0.384056</td>\n",
       "      <td>0.031204</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>0.999847</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.040000</td>\n",
       "      <td>0.120000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            %_Change      Adj Close          Close           High  \\\n",
       "count  145249.000000  145249.000000  145249.000000  145249.000000   \n",
       "mean      -14.587246       0.260711       0.260711       0.258983   \n",
       "std       241.445658       0.233928       0.233928       0.233008   \n",
       "min     -6817.181855       0.000002       0.000002       0.000003   \n",
       "25%        -0.022472       0.071907       0.071907       0.071415   \n",
       "50%         0.000000       0.186074       0.186074       0.183905   \n",
       "75%         0.023364       0.387178       0.387178       0.384500   \n",
       "max         0.999847       1.000000       1.000000       1.000000   \n",
       "\n",
       "                 Low          Low_1          Max_1       Moving10  \\\n",
       "count  145249.000000  145249.000000  145249.000000  145249.000000   \n",
       "mean        0.262354      -0.028830       0.029378       0.280289   \n",
       "std         0.234513       0.039775       0.043007       0.244531   \n",
       "min         0.000002      -0.100000      -0.030000       0.000006   \n",
       "25%         0.073402      -0.060000       0.000000       0.082165   \n",
       "50%         0.187259      -0.030000       0.020000       0.203135   \n",
       "75%         0.387692       0.000000       0.050000       0.414505   \n",
       "max         1.000000       0.040000       0.120000       1.000000   \n",
       "\n",
       "            Moving30           Open         Volume  \n",
       "count  145249.000000  145249.000000  145249.000000  \n",
       "mean        0.300724       0.259255       0.026125  \n",
       "std         0.256038       0.233414       0.050913  \n",
       "min         0.000482       0.000003       0.000000  \n",
       "25%         0.091947       0.071223       0.002690  \n",
       "50%         0.222163       0.183868       0.011252  \n",
       "75%         0.448409       0.384056       0.031204  \n",
       "max         1.000000       1.000000       1.000000  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_in_list = []\n",
    "for stock in stocks:\n",
    "    stock_dict_list = data[stock]\n",
    "    for index, dict_ in enumerate(stock_dict_list):\n",
    "        list_ = []\n",
    "        list_h = []\n",
    "        for i in range(low_range[0],low_range[1]):\n",
    "            if dict_['Low_1'] == i/100:\n",
    "                list_.append(1)\n",
    "            else:\n",
    "                list_.append(0)\n",
    "        for i in range(high_range[0],high_range[1]):\n",
    "            if dict_['Max_1'] == i/100:\n",
    "                list_h.append(1)\n",
    "            else:\n",
    "                list_h.append(0)\n",
    "        \n",
    "        stock_dict_list[index]['Data_'] = list_\n",
    "        dict_['Data_'] = list_\n",
    "        stock_dict_list[index]['Data_High'] = list_h\n",
    "        dict_['Data_High'] = list_h\n",
    "        data_in_list.append(dict_)\n",
    "        \n",
    "        low_target_length = len(list_)\n",
    "        high_target_length = len(list_h)\n",
    "    data[stock] = stock_dict_list\n",
    "df = pd.DataFrame(data_in_list) \n",
    "df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "DLYnbjYeyu0y"
   },
   "outputs": [],
   "source": [
    "processed_data = {}\n",
    "\n",
    "for stock in stocks:\n",
    "    x = []\n",
    "    target = []\n",
    "    target_h = []\n",
    "    dict_ = {}\n",
    "    for i in data[stock]:\n",
    "        row =np.array([i['High'], i['Low'], i['Open'], i['Close'], i['Adj Close'], i['Volume'], i['%_Change']]) #, i['Moving10'], i['Moving30']])\n",
    "        data_length = len(row)\n",
    "        x.append(row)\n",
    "        row = np.array(i['Data_'])\n",
    "        target.append(row)\n",
    "        row = np.array(i['Data_High'])\n",
    "        target_h.append(row)\n",
    "    dict_['Data'] = x\n",
    "    dict_['Target'] = target\n",
    "    dict_['Target_High'] =target_h\n",
    "    processed_data[stock] = dict_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "mxB68JDiJZ7M"
   },
   "outputs": [],
   "source": [
    "for stock in stocks:\n",
    "    length_ = len(processed_data[stock]['Data'])\n",
    "    length_test = len(processed_data[stock]['Data'])//8\n",
    "    test_start = length_- 100\n",
    "    test_end = length_test+ test_start\n",
    "    processed_data[stock]['data_1'] = np.array(processed_data[stock]['Data'][:test_start])\n",
    "    processed_data[stock]['data_1'] =   processed_data[stock]['data_1'].reshape(len(processed_data[stock]['data_1']), 1, data_length)\n",
    "    processed_data[stock]['data_test'] = np.array(processed_data[stock]['Data'][test_start:-10])\n",
    "    processed_data[stock]['data_test'] = processed_data[stock]['data_test'].reshape(len(processed_data[stock]['data_test']),1, data_length)\n",
    "    transfer_list = np.array(processed_data[stock]['Target'][:test_start])\n",
    "    processed_data[stock]['target_1'] =transfer_list.reshape(len(transfer_list), low_target_length)\n",
    "    transfer_list = np.array(processed_data[stock]['Target'][test_start:-10])\n",
    "    processed_data[stock]['target_test'] = transfer_list.reshape(len(transfer_list),low_target_length)\n",
    "    transfer_list = np.array(processed_data[stock]['Target_High'][:test_start])\n",
    "    processed_data[stock]['target_high'] =transfer_list.reshape(len(transfer_list), high_target_length)\n",
    "    transfer_list = np.array(processed_data[stock]['Target_High'][test_start:-10])\n",
    "    processed_data[stock]['target_high_test'] = transfer_list.reshape(len(transfer_list),high_target_length)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 266
    },
    "colab_type": "code",
    "id": "gxJmCXmt6DjZ",
    "outputId": "4cce03cc-ade7-4139-a9c6-f2e194a2f754"
   },
   "outputs": [],
   "source": [
    "model = models.Sequential()\n",
    "model.add(layers.GRU(25, return_sequences=True, input_shape=(1,data_length)))\n",
    "model.add(layers.Dropout(0.5))\n",
    "model.add(layers.GRU(50, return_sequences=False))\n",
    "model.add(layers.Dropout(0.5))\n",
    "model.add(layers.Dense(low_target_length, activation = \"softmax\"))\n",
    "model.compile(loss='categorical_crossentropy',\n",
    "              optimizer='adam', metrics=['accuracy'])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "epochs = 50\n",
    "for stock in stocks:\n",
    "    (feature_train, label_train, feature_test, label_test) = (processed_data[stock]['data_1'],processed_data[stock]['target_1'], \n",
    "                                                                    processed_data[stock]['data_test'],\n",
    "                                                              processed_data[stock]['target_test']) \n",
    "    model.fit(feature_train, label_train, batch_size=25, epochs=epochs, \n",
    "              validation_data = (feature_test, label_test), verbose=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "colab_type": "code",
    "id": "gWTDi1NMBdIe",
    "outputId": "dc3859c3-8a10-4841-88e9-1d5cba68295d",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "epochs = 10\n",
    "loss = []\n",
    "val_loss = []   \n",
    "acc = []\n",
    "val_acc = []\n",
    "rank = []\n",
    "check = 0\n",
    "for run in range(1,500):\n",
    "    stock = 'SGMO'\n",
    "    (feature_train, label_train, feature_test, label_test) = (processed_data[stock]['data_1'],processed_data[stock]['target_1'], \n",
    "                                                                    processed_data[stock]['data_test'],\n",
    "                                                              processed_data[stock]['target_test']) \n",
    "    model.fit(feature_train, label_train, batch_size=25, epochs=epochs, \n",
    "              validation_data = (feature_test, label_test), verbose=0)\n",
    "    dict_ = model.history.history\n",
    "\n",
    "    for i in dict_['loss']:\n",
    "        loss.append(i)\n",
    "\n",
    "    for i in dict_['val_loss']:\n",
    "        val_loss.append(i)\n",
    "\n",
    "    for i in dict_['acc']:\n",
    "        acc.append(i)\n",
    "\n",
    "    for i in dict_['val_acc']:\n",
    "        val_acc.append(i)\n",
    "\n",
    "    \n",
    "    \n",
    "    X = np.array(processed_data[stock]['Data']).reshape(len(processed_data[stock]['Data']), 1, data_length)\n",
    "    predict = model.predict(X)\n",
    "    transfer_dict = {'Epochs':(run*epochs), 'Rank':label_ranking_average_precision_score(processed_data[stock]['Target'][-100], predict[-100:])}\n",
    "     \n",
    "    if check <= transfer_dict['Rank']:\n",
    "        filepath = 'Models\\Model_GRU_cat_Low_1SGMO.h5'\n",
    "        model.save_weights(filepath)\n",
    "        check = transfer_dict['Rank']\n",
    "        rank.append(transfer_dict)\n",
    "        print(transfer_dict)\n",
    "\n",
    "plt.plot([i['Epochs'] for i in rank], [i['Rank'] for i in rank], 'b', label='Label Ranking')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "list_= []\n",
    "predict_list = []\n",
    "true_list = []\n",
    "for stock in stocks:\n",
    "    X = np.array(processed_data[stock]['Data']).reshape(len(processed_data[stock]['Data']), 1, data_length)\n",
    "    predict = model.predict(X)\n",
    "    for index, i in enumerate(predict):\n",
    "        predict_list.append(i)\n",
    "        true_list.append(processed_data[stock]['Target'][index])\n",
    "    list_.append({'Ticker':stock, 'Ranking':label_ranking_average_precision_score(processed_data[stock]['Target'], predict)})\n",
    "                  \n",
    "df = pd.DataFrame(list_)\n",
    "df.sort_values('Ranking', ascending=False).head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "columns = [i for i in range(low_range[0],low_range[1])]\n",
    "columns = np.array(columns)/100\n",
    "for column, name in enumerate(columns):\n",
    "    transfer_list = []\n",
    "    for index, target in enumerate(true_list):\n",
    "        if target[column] == 1:\n",
    "            transfer_list.append(predict_list[index])\n",
    "    plt.figure(figsize=(8,5))\n",
    "    pd.DataFrame(transfer_list, columns=columns).mean().plot.bar().set_title(name)\n",
    "    plt.vlines(column, 0,.1)\n",
    "    plt.show"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "\n",
    "X = np.array(processed_data['SGMO']['Data']).reshape(len(processed_data['SGMO']['Data']), 1, data_length)\n",
    "predict = model.predict(X)\n",
    "\n",
    "for column, name in enumerate(columns):\n",
    "    transfer_list = []\n",
    "    for index, target in enumerate(processed_data['SGMO']['Target']):\n",
    "        if target[column] == 1:\n",
    "            transfer_list.append(predict[index])\n",
    "    plt.figure(figsize=(8,5))\n",
    "    pd.DataFrame(transfer_list, columns=columns).mean().plot.bar().set_title(name)\n",
    "    plt.vlines(column, 0,.05)\n",
    "    plt.show   \n",
    "                  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = models.Sequential()\n",
    "model.add(layers.GRU(25, return_sequences=True, input_shape=(1,data_length)))\n",
    "model.add(layers.Dropout(0.5))\n",
    "model.add(layers.GRU(50, return_sequences=False))\n",
    "model.add(layers.Dropout(0.5))\n",
    "model.add(layers.Dense(high_target_length, activation = \"softmax\"))\n",
    "model.compile(loss='categorical_crossentropy',\n",
    "              optimizer='adam', metrics=['accuracy'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "epochs = 50\n",
    "for stock in stocks:\n",
    "    (feature_train, label_train, feature_test, label_test) = (processed_data[stock]['data_1'],\n",
    "                                                              processed_data[stock]['target_high'], \n",
    "                                                                    processed_data[stock]['data_test'],\n",
    "                                                              processed_data[stock]['target_high_test']) \n",
    "    model.fit(feature_train, label_train, batch_size=25, epochs=epochs, \n",
    "              validation_data = (feature_test, label_test), verbose=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "epochs = 10\n",
    "lossh = []\n",
    "val_lossh = []   \n",
    "acch = []\n",
    "val_acch = []\n",
    "rankh = []\n",
    "\n",
    "for run in range(1,5000):\n",
    "    stock = 'SGMO'\n",
    "    (feature_train, label_train, feature_test, label_test) = (processed_data[stock]['data_1'],\n",
    "                                                              processed_data[stock]['target_high'], \n",
    "                                                              processed_data[stock]['data_test'],\n",
    "                                                              processed_data[stock]['target_high_test']) \n",
    "    model.fit(feature_train, label_train, batch_size=25, epochs=epochs, \n",
    "              validation_data = (feature_test, label_test), verbose=0)\n",
    "    dict_ = model.history.history\n",
    "\n",
    "    for i in dict_['loss']:\n",
    "        lossh.append(i)\n",
    "\n",
    "    for i in dict_['val_loss']:\n",
    "        val_lossh.append(i)\n",
    "\n",
    "    for i in dict_['acc']:\n",
    "        acch.append(i)\n",
    "\n",
    "    for i in dict_['val_acc']:\n",
    "        val_acch.append(i)\n",
    "\n",
    "    \n",
    "    X = np.array(processed_data[stock]['Data']).reshape(len(processed_data[stock]['Data']), 1, data_length)\n",
    "    predict = model.predict(X)\n",
    "    transfer_dict = {'Epochs':(run*epochs),\n",
    "                     'Rank':label_ranking_average_precision_score(processed_data[stock]['Target_High'][-100:],\n",
    "                                                                  predict[-100:])}\n",
    "    \n",
    "    if check <= transfer_dict['Rank']:\n",
    "        filepath = 'Models\\Model_GRU_cat_High_1SGMO.h5'\n",
    "        model.save_weights(filepath)\n",
    "        check = transfer_dict['Rank']\n",
    "        rankh.append(transfer_dict)\n",
    "        print(transfer_dict)\n",
    "    \n",
    "plt.plot([i['Epochs'] for i in rank], [i['Rank'] for i in rankh], 'b', label='Label Ranking')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "columns = [i for i in range(high_range[0],high_range[1])]\n",
    "columns = np.array(columns)/100\n",
    "for column, name in enumerate(columns):\n",
    "    transfer_list = []\n",
    "    for index, target in enumerate(true_list):\n",
    "        if target[column] == 1:\n",
    "            transfer_list.append(predict_list[index])\n",
    "    plt.figure(figsize=(8,5))\n",
    "    pd.DataFrame(transfer_list, columns=columns).mean().plot.bar().set_title(name)\n",
    "    plt.vlines(column, 0,.1)\n",
    "    plt.show"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "list_= []\n",
    "predict_list = []\n",
    "true_list = []\n",
    "for stock in stocks:\n",
    "    X = np.array(processed_data[stock]['Data']).reshape(len(processed_data[stock]['Data']), 1, data_length)\n",
    "    predict = model.predict(X)\n",
    "    for index, i in enumerate(predict):\n",
    "        predict_list.append(i)\n",
    "        true_list.append(processed_data[stock]['Target_High'][index])\n",
    "    list_.append({'Ticker':stock, 'Ranking':label_ranking_average_precision_score(processed_data[stock]['Target_High'], predict)})\n",
    "                  \n",
    "df = pd.DataFrame(list_)\n",
    "df.sort_values('Ranking', ascending=False).head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "columns = np.array([i for i in range(high_range[0],high_range[1])])/100\n",
    "X = np.array(processed_data['SGMO']['Data']).reshape(len(processed_data['SGMO']['Data']), 1, data_length)\n",
    "predict = model.predict(X)\n",
    "\n",
    "for column, name in enumerate(columns):\n",
    "    transfer_list = []\n",
    "    for index, target in enumerate(processed_data['SGMO']['Target_High']):\n",
    "        if target[column] == 1:\n",
    "            transfer_list.append(predict[index])\n",
    "    plt.figure(figsize=(8,5))\n",
    "    pd.DataFrame(transfer_list, columns=columns).mean().plot.bar().set_title(name)\n",
    "    plt.vlines(column, 0,.05)\n",
    "    plt.show   \n",
    "                  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = np.random.choice(columns, 1000, p=predict[-1])\n",
    "a = [i + np.random.random()/100-0.005 for i in a]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "sns.distplot(a)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Plot Medians of Predicted versus True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.load_weights('Models/Model_GRU_cat_Low_1SGMO.h5')\n",
    "\n",
    "X = np.array(processed_data['SGMO']['Data']).reshape(len(processed_data['SGMO']['Data']), 1, data_length)\n",
    "predict = model.predict(X)\n",
    "columns = np.array([i for i in range(low_range[0],low_range[1])])/100\n",
    "predict_medians= []\n",
    "predict_25 = []\n",
    "for i in predict:\n",
    "    \n",
    "    a = np.random.choice(columns, 1000, p=i)\n",
    "    a = [i + np.random.random()/100-0.005 for i in a]\n",
    "    predict_medians.append(np.median(a))\n",
    "    predict_25.append(np.quantile(a, 0.25))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "target =  [dict_['Low_1'] for dict_ in data['SGMO']]\n",
    "open_price = [dict_['Open'] for dict_ in data['SGMO']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(13,5), )\n",
    "plt.rcParams.update({'font.size': 12})\n",
    "plt.plot(list(range(0,100)), target[-100:], label= 'True')\n",
    "plt.plot(list(range(0,100)), predict_medians[-100:],  label= 'Predict Median')\n",
    "plt.title('Predicted Medians for Ticker SGMO vs. True Percent \\n Difference for Open Price')\n",
    "plt.show()\n",
    "\n",
    "plt.figure(figsize=(13,5), )\n",
    "plt.rcParams.update({'font.size': 12})\n",
    "plt.plot(list(range(0,100)), target[-100:], label= 'True')\n",
    "plt.plot(list(range(0,100)), predict_25[-100:],  label= 'Predict Median')\n",
    "plt.title('Predicted 25th Quantile for Ticker SGMO vs. True Percent \\n Difference for Open Price')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import r2_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(r2_score(target, predict_medians), r2_score(target, predict_25))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(13,5))\n",
    "plt.title(f\"{stock} Residual Distribution for Medians vs.True Percent \\n Difference for Open Price\")\n",
    "residuals = [i-j for i,j in zip(predict_medians,target)]\n",
    "sns.distplot(residuals, label = 'Residual Medians', hist=False)\n",
    "low_interval = np.median(residuals)- np.std(residuals) \n",
    "high_interval = np.median(residuals)+ np.std(residuals) \n",
    "plt.vlines(low_interval, 0 , 25, colors= 'b', label='Medians Confidence Intervals')\n",
    "plt.vlines(high_interval, 0 , 25, colors= 'b')\n",
    "residuals = [i-j for i,j in zip(predict_25,target)]\n",
    "sns.distplot(residuals, label = 'Residual 25th Quantile', hist=False)\n",
    "low_interval = np.median(residuals)- np.std(residuals) \n",
    "high_interval = np.median(residuals)+ np.std(residuals) \n",
    "plt.vlines(low_interval, 0 , 25, colors= 'orange', label='25th Confidence Intervals')\n",
    "plt.vlines(high_interval, 0 , 25, colors= 'orange')\n",
    "plt.legend(bbox_to_anchor=(1.05, 1))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Display Prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.load_weights('Models/Model_GRU_cat_Low_1SGMO_8450epoch.h5')\n",
    "low_model = model\n",
    "model.load_weights('Models/Model_GRU_cat_High_1SGMO_8050epoch.h5')\n",
    "high_model = model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "name": "data_retrieval.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
